# tark Configuration
# Tark - Default Configuration
# Copy this file to ~/.config/tark/config.toml

[llm]
# Default LLM provider: "claude", "openai", "tark_sim", or "ollama"
default_provider = "tark_sim"

[llm.claude]
model = "claude-sonnet-4-20250514"
max_tokens = 4096

[llm.openai]
model = "gpt-4o"
max_tokens = 4096

[llm.ollama]
# Local Ollama server URL
base_url = "http://localhost:11434"
# Model to use (run `ollama list` to see available models)
# Good coding models: codellama, deepseek-coder, qwen2.5-coder, starcoder2
# Note: Available models are loaded dynamically from your local Ollama instance
model = "codellama"

[server]
host = "127.0.0.1"
port = 8765

[completion]
enabled = true
# Debounce delay before triggering completion (ms)
debounce_ms = 150
# Maximum tokens for completion responses
max_completion_tokens = 256
# Number of cached completions
cache_size = 100
# Context lines to include
context_lines_before = 50
context_lines_after = 20

[agent]
# Maximum tool call iterations per query (increase for complex multi-step tasks)
max_iterations = 50
# Default working directory (. = current directory)
working_directory = "."

[tools]
# Enable shell command execution
shell_enabled = true
# Allowed paths for file operations (relative to working directory)
allowed_paths = ["."]

# TUI (Terminal User Interface) Configuration
[tui]
# Default theme preset
# Options: catppuccin_mocha, catppuccin_macchiato, catppuccin_frappe, catppuccin_latte,
#          nord, tokyo_night, gruvbox_dark, gruvbox_light,
#          solarized_dark, solarized_light, one_dark
# Note: Sessions can override this theme, but this sets the default for new sessions
theme = "catppuccin_mocha"

