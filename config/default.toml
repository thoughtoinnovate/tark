# tark Configuration
# Tark - Default Configuration
# Copy this file to ~/.config/tark/config.toml

[llm]
# Default LLM provider: "claude", "openai", or "ollama"
default_provider = "openai"

[llm.claude]
model = "claude-sonnet-4-20250514"
max_tokens = 4096

[llm.openai]
model = "gpt-4o"
max_tokens = 4096

[llm.ollama]
# Local Ollama server URL
base_url = "http://localhost:11434"
# Model to use (run `ollama list` to see available models)
# Good coding models: codellama, deepseek-coder, qwen2.5-coder, starcoder2
model = "codellama"

[server]
host = "127.0.0.1"
port = 8765

[completion]
enabled = true
# Debounce delay before triggering completion (ms)
debounce_ms = 150
# Maximum tokens for completion responses
max_completion_tokens = 256
# Number of cached completions
cache_size = 100
# Context lines to include
context_lines_before = 50
context_lines_after = 20

[agent]
# Maximum tool call iterations per query
max_iterations = 25
# Default working directory (. = current directory)
working_directory = "."

[tools]
# Enable shell command execution
shell_enabled = true
# Allowed paths for file operations (relative to working directory)
allowed_paths = ["."]

# TUI (Terminal User Interface) Configuration
[tui.attachments]
# Maximum file size for attachments in bytes (default: 10MB)
max_attachment_size = 10485760
# Maximum number of attachments per message (default: 10)
max_attachments = 10

[tui.theme]
# Theme name: "dark" or "light"
name = "dark"

# Optional custom colors (uncomment to override)
# [tui.theme.colors]
# primary = "cyan"
# secondary = "magenta"
# background = "#1e1e1e"
# foreground = "#d4d4d4"
# error = "red"
# warning = "yellow"
# success = "green"

# Custom keybindings (uncomment to override defaults)
# [tui.keybindings.custom]
# quit = "Ctrl-q"
# submit = "Ctrl-Enter"

